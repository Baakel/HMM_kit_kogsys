{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data 1 loaded: (10000, 50)\n",
      "Train data 2 loaded: (10000, 50)\n",
      "Train data 3 loaded: (10000, 50)\n",
      "Train data 4 loaded: (10000, 50)\n",
      "Train data 5 loaded: (10000, 50)\n",
      "Development data loaded: 500\n",
      "\n",
      "Starting initial probabilities:\n",
      "[0.2 0.1 0.2 0.2 0.2 0.1]\n",
      "initial[i] is the probability of starting in state i\n",
      "\n",
      "Starting transition probabilities:\n",
      "[[0.3 0.3 0.1 0.1 0.1 0.1]\n",
      " [0.1 0.3 0.3 0.1 0.1 0.1]\n",
      " [0.1 0.1 0.3 0.3 0.1 0.1]\n",
      " [0.1 0.1 0.1 0.3 0.3 0.1]\n",
      " [0.1 0.1 0.1 0.1 0.3 0.3]\n",
      " [0.3 0.1 0.1 0.1 0.1 0.3]]\n",
      "transition[i,j] is the probability of transitioning from state i to state j\n",
      "\n",
      "Starting emission probabilities\n",
      "[[0.2 0.2 0.1 0.1 0.1 0.1]\n",
      " [0.2 0.2 0.2 0.2 0.1 0.1]\n",
      " [0.2 0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2 0.2]\n",
      " [0.1 0.1 0.2 0.2 0.2 0.2]\n",
      " [0.1 0.1 0.1 0.1 0.2 0.2]]\n",
      "emission[v,i] is the probability of emitting v in state i\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "\n",
    "with open(\"data/model_init.txt\") as model_init:\n",
    "    model_init.readline() # \"initial: 6\"\n",
    "    initial = np.array([float(x) for x in model_init.readline().split()])\n",
    "    model_init.readline()\n",
    "    model_init.readline() # \"transition: 6\"\n",
    "    transition = np.array([[float(x) for x in model_init.readline().split()]\n",
    "                           for _ in range(6)])\n",
    "    model_init.readline()\n",
    "    model_init.readline() # \"emission: 6\"\n",
    "    emission = np.array([[float(x) for x in model_init.readline().split()]\n",
    "                          for _ in range(6)])\n",
    "\n",
    "vocabulary = \"ABCDEF\"\n",
    "lookup = {letter: index for index, letter in enumerate(vocabulary)}\n",
    "train_data = []\n",
    "for i in range(1, 6):\n",
    "    train_data_i = []\n",
    "    with open(f\"data/seq_model_0{i}.txt\") as data:\n",
    "        for line in data:\n",
    "            train_data_i.append(np.array([lookup[letter] for letter in line.rstrip()]))\n",
    "    train_data.append(np.array(train_data_i))\n",
    "    print(f\"Train data {i} loaded: {train_data[i-1].shape}\")\n",
    "\n",
    "with open(f\"data/dev_data.txt\") as data:\n",
    "    dev_data = []\n",
    "    for line in data:\n",
    "        sequence, label = line.split(\"\\t\")\n",
    "        sequence = np.array([lookup[letter] for letter in sequence])\n",
    "        label = int(label) - 1\n",
    "        dev_data.append((sequence, label))\n",
    "print(f\"Development data loaded: {len(dev_data)}\")\n",
    "\n",
    "print()\n",
    "print(\"Starting initial probabilities:\")\n",
    "print(initial)\n",
    "print(\"initial[i] is the probability of starting in state i\")\n",
    "print()\n",
    "print(\"Starting transition probabilities:\")\n",
    "print(transition)\n",
    "print(\"transition[i,j] is the probability of transitioning from state i to state j\")\n",
    "print()\n",
    "print(\"Starting emission probabilities\")\n",
    "print(emission)\n",
    "print(\"emission[v,i] is the probability of emitting v in state i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, initial, transition, emission):\n",
    "        self.initial = initial.copy()\n",
    "        self.transition = transition.copy()\n",
    "        self.emission = emission.copy()\n",
    "        self.num_emissions, self.num_states = emission.shape\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, \"wb\") as out_file:\n",
    "            np.savez(out_file, initial=self.initial, transition=self.transition, emission=self.emission)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, \"rb\") as in_file:\n",
    "            arrays = np.load(in_file)\n",
    "            hmm = cls(arrays[\"initial\"], arrays[\"transition\"], arrays[\"emission\"])\n",
    "            arrays.close()\n",
    "        return hmm\n",
    "    \n",
    "    def forward(self, observation):\n",
    "        # Input: int array of size (length,). observation[t] is the observation at time t\n",
    "        # Output: forward trellis - double array of size (length, self.num_states)\n",
    "        length = len(observation)\n",
    "        alpha = np.zeros((length, self.num_states), dtype=np.double)\n",
    "        alpha[0] = self.initial * self.emission[observation[0]]\n",
    "        for t in range(1, length):\n",
    "            alpha[t] = np.matmul(alpha[t-1], self.transition) * self.emission[observation[t]]\n",
    "        return alpha\n",
    "    \n",
    "    def forward_batch(self, observations):\n",
    "        # OPTIONAL\n",
    "        # Input: int array of size (length, num_observations). observation[t, i] is the observation at time t in sequence i\n",
    "        # Output: forward trellis - double array of size (length, num_observations, self.num_states)\n",
    "        length, num_observations = observations.shape\n",
    "        alpha = np.zeros((length, num_observations, self.num_states), dtype=np.double)\n",
    "        alpha[0] = self.initial * self.emission[observations[0]]\n",
    "        for t in range(1, length):\n",
    "            alpha[t] = np.matmul(alpha[t-1], self.transition) * self.emission[observations[t]]\n",
    "        return alpha\n",
    "\n",
    "        \n",
    "    def backward(self, observation):\n",
    "        # Input: int array of size (length,). observation[t] is the observation at time t\n",
    "        # Output: backward trellis - double array of size (length, self.num_states)\n",
    "        length = len(observation)\n",
    "        beta = np.zeros((length, self.num_states), dtype=np.double)\n",
    "        beta[length-1] = 1\n",
    "        for t in reversed(range(length-1)):\n",
    "            beta[t] = np.matmul(self.emission[observation[t+1]] * beta[t+1], self.transition.T)\n",
    "        return beta\n",
    "    \n",
    "    def backward_batch(self, observations):\n",
    "        # OPTIONAL\n",
    "        # Input: int array of size (length, num_observations). observation[t, i] is the observation at time t in sequence i\n",
    "        # Output: backward trellis - double array of size (length, num_observations, self.num_states)\n",
    "        length, num_observations = observations.shape\n",
    "        beta = np.zeros((length, num_observations, self.num_states), dtype=np.double)\n",
    "        beta[length-1] = 1\n",
    "        for t in reversed(range(length-1)):\n",
    "            beta[t] = np.matmul(self.emission[observations[t+1]] * beta[t+1], self.transition.T)\n",
    "        return beta\n",
    "        \n",
    "    def viterbi(self, observation):\n",
    "        # Input: int array of size (length,). observation[t] is the observation at time t\n",
    "        # Output: tuple with (viterbi_path, likelihood)\n",
    "        # viterbi_path is an int array of size (length,). viterbi_path[t] is state at time t in the most likely state sequence.\n",
    "        # likelihood: double scalar. The probability of the most likely path given the observation\n",
    "        length = len(observation)\n",
    "        delta = np.zeros((length, self.num_states), dtype=np.double)\n",
    "        psi = np.zeros((length-1, self.num_states), dtype=int)\n",
    "        delta[0] = self.initial * self.emission[observation[0]]\n",
    "\n",
    "        for t in range(1, length):\n",
    "            inner = delta[t-1, :, None] * self.transition\n",
    "            delta[t] = np.max(inner, 0) * self.emission[observation[t]]\n",
    "            psi[t-1] = np.argmax(inner, 0)\n",
    "\n",
    "        best_path = np.empty((length,), dtype=int)\n",
    "        probability = np.max(delta[length-1])\n",
    "        best_path[length-1] = np.argmax(delta[length-1])\n",
    "        for t in reversed(range(length-1)):\n",
    "            best_path[t] = psi[t, best_path[t+1]]\n",
    "        return best_path, probability\n",
    "        \n",
    "    def baum_welch(self, observations):\n",
    "        # Input: int array of size (num_observations, length). Each observations[i] is an independent observation sequence. observations[i, t] is the observation in sample i at time t\n",
    "        # Output: likelihoods: double array of size (num_observations,). likelihoods[i] is the probability of observing the sequence observations[i] given the (old) model parameters\n",
    "        # Side Effect: Update self.initial, self.transition and self.emission according to the Baum-Welch reestimation rule for multiple observation sequences.\n",
    "        num_observations, length = observations.shape\n",
    "        observations = np.ascontiguousarray(observations.T)\n",
    "        alpha = self.forward_batch(observations)\n",
    "        beta = self.backward_batch(observations)\n",
    "\n",
    "        assert alpha.shape == beta.shape == (length, num_observations, self.num_states)\n",
    "\n",
    "        observation_probability = alpha[-1].sum(1)\n",
    "        gamma = alpha * beta / observation_probability[np.newaxis, :, np.newaxis]\n",
    "        xi = alpha[:length-1, :, :, np.newaxis] * self.transition * (beta * self.emission[observations])[1:, :, np.newaxis, :]\n",
    "        xi /= observation_probability[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "\n",
    "        assert gamma.shape == (length, num_observations, self.num_states)\n",
    "        assert xi.shape == (length-1, num_observations, self.num_states, self.num_states)\n",
    "\n",
    "        self.initial[:] = gamma[0].mean(0)\n",
    "        self.transition[:] = xi.sum(axis=(0,1)) / gamma[:length-1].sum(axis=(0,1))\n",
    "        sum_gamma = gamma.sum(axis=(0,1))\n",
    "        for vk in range(self.num_emissions):\n",
    "            self.emission[vk] = gamma[observations == vk].sum(0) / sum_gamma\n",
    "        return observation_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8bfe425b2504661800e7d28659a8580"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e022b10954e849ff80f70fff6a9db94b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c8a15ba48ed4729b287c514c33abff3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e880590c230548dcbd5ca0eee55ec3be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d67f45f3ccc4191b2b8478408a5125f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "hmms = [HMM(initial, transition, emission) for i in range(5)]\n",
    "batch_size = 50\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "for n,(dataset, hmm) in enumerate(zip(train_data, hmms)):\n",
    "    pbar = tqdm(total=len(dataset))\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        likelihood = hmm.baum_welch(dataset[i:i+batch_size])\n",
    "        pbar.set_description(f\"log-likelihood: {np.mean(np.log(likelihood)):.2f}\")\n",
    "        pbar.update(batch_size)\n",
    "    pbar.close()\n",
    "    hmm.save(os.path.join(\"models\", f\"model_{n+1}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3ef11ff35fe4d10b4346175547b2bae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.6%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "pbar = tqdm(total=len(dev_data))\n",
    "for sample, label in dev_data:\n",
    "    decision = np.argmax([hmm.viterbi(sample)[1] for hmm in hmms])\n",
    "    correct += (decision == label)\n",
    "    pbar.update()\n",
    "pbar.close()\n",
    "print(f\"Accuracy: {correct / len(dev_data):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}